{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "torch.set_grad_enabled(False)  # 关闭梯度计算\n",
    "\n",
    "# COCO classes\n",
    "CLASSES = [\n",
    "    'N/A', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A',\n",
    "    'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',\n",
    "    'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack',\n",
    "    'umbrella', 'N/A', 'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis',\n",
    "    'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
    "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass',\n",
    "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',\n",
    "    'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
    "    'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A',\n",
    "    'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
    "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A',\n",
    "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
    "    'toothbrush'\n",
    "]\n",
    "# standard PyTorch mean-std input image normalization\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(800),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 加载线上的模型与参数\n",
    "model = torch.hub.load(\"facebookresearch/detr\", \"detr_resnet50\", pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# 线上下载图像 (图像获取不到的话，就自己换一张图)\n",
    "url = \"http://farm3.staticflickr.com/2750/4078616721_d76a64a6bb_z.jpg\"\n",
    "im = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "# 预处理图像 (batch-size: 1)\n",
    "img = transform(im).unsqueeze(0)\n",
    "\n",
    "# 预测结果\n",
    "outputs = model(img)\n",
    "\n",
    "# 只保留 confidence > 0.9 的预测结果\n",
    "probas = outputs[\"pred_logits\"].softmax(-1)[0, :, :-1]\n",
    "keep = probas.max(-1).values > 0.9\n",
    "\n",
    "# 获取 bbox 中心坐标\n",
    "cxcy = outputs[\"pred_boxes\"][0, keep, :2]\n",
    "\n",
    "# 获取 预测类别 和 置信度\n",
    "confidence, predicted_cats = outputs[\"pred_logits\"][0, keep].softmax(-1).max(-1)\n",
    "predicted_cats_name = [CLASSES[cat] for cat in predicted_cats]\n",
    "\n",
    "# use lists to store the outputs via up-values\n",
    "conv_features = []\n",
    "enc_attn_weights = []\n",
    "\n",
    "# 注册hook\n",
    "hooks = [\n",
    "    # 获取resnet最后一层特征图，目的是获取 特征图的尺寸\n",
    "    model.backbone[-2].register_forward_hook(\n",
    "        lambda self, input, output: conv_features.append(output[\"0\"].tensors)\n",
    "    ),\n",
    "    # 获取最后一个 encoder layer的 self-attn weights\n",
    "    model.transformer.encoder.layers[-1].self_attn.register_forward_hook(\n",
    "        lambda self, input, output: enc_attn_weights.append(output[1])\n",
    "    ),\n",
    "]\n",
    "\n",
    "# 前向传播，获取 hook 注册的中检测输出\n",
    "outputs = model(img)\n",
    "\n",
    "# 用完的hook后删除\n",
    "for hook in hooks:\n",
    "    hook.remove()\n",
    "\n",
    "# don't need the list anymore\n",
    "enc_attn_weights = enc_attn_weights[0]  # [1, 950, 950]\n",
    "conv_features = conv_features[0]  # [1,2048,25,38]\n",
    "\n",
    "\n",
    "# 获取 feature map 尺寸\n",
    "h, w = conv_features.shape[-2:]\n",
    "# cxcy = torch.floor(cxcy * torch.tensor([w, h]))\n",
    "enc_attn_weights = enc_attn_weights.view(h, w, h * w)\n",
    "\n",
    "\n",
    "# 可视化\n",
    "fig, axs = plt.subplots(ncols=1, nrows=len(cxcy) + 1, figsize=(10, 12))\n",
    "\n",
    "# 在原图上标注 reference point\n",
    "ax = axs[0]\n",
    "ax.axis(\"off\")\n",
    "ax.imshow(im)\n",
    "\n",
    "\"\"\"\n",
    "# 我们求出的 bbox 的中心点坐标为 tensor([[171., 143.], [438., 135.]])， 它不是正好在 object 主体上\n",
    "# 可以做适当的调整（人工手动选择），调整后的坐标值作为 reference point，\n",
    "# 下面会可视化 reference point 的 attention map\n",
    "# 我们将 reference point 的坐标调整为 ：[[210., 90.], [400., 100.]]\n",
    "\"\"\"\n",
    "\n",
    "# reference_points = torch.floor(cxcy / torch.tensor([w, h]) * torch.tensor([im.width, im.height]))   # tensor([[171., 143.], [438., 135.]])\n",
    "\n",
    "reference_points = torch.tensor([[210.0, 90.0], [400.0, 100.0]])\n",
    "ax.scatter(reference_points[:, 0], reference_points[:, 1], color=\"red\", marker=\"o\")\n",
    "\n",
    "for ax, reference_point in zip(axs[1:], reference_points):\n",
    "    x = (reference_point[0] / im.width * w).type(torch.long)\n",
    "    y = (reference_point[1] / im.height * h).type(torch.long)\n",
    "    attention_meap = enc_attn_weights[y, x, :].view(h, w).unsqueeze(-1)\n",
    "\n",
    "    ax.imshow(attention_meap, cmap=\"cividis\")\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(\n",
    "        f\"self-attention: ({int(reference_point[0])}, {int(reference_point[1])})\",\n",
    "        fontsize=20,\n",
    "    )\n",
    "\n",
    "fig.tight_layout()  # 自动调整子图来使其填充整个画布\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mojo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
